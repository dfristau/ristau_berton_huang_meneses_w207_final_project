{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from collections import Counter\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "#from imblearn.over_sampling import SVMSMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import consolidated saved csvs of wav features\n",
    "\n",
    "train_wav = pd.read_csv('../data/df_train_wav_consolidated.csv',index_col=0)\n",
    "test_wav = pd.read_csv('../data/df_test_wav_finc.csv',index_col=0)\n",
    "\n",
    "#Get metadata\n",
    "metadata=pd.read_csv('../data/musicnet_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the metadata\n",
    "meta_data_copy = metadata.copy(deep=True)\n",
    "meta_data_copy.reset_index(inplace=True)\n",
    "#Rename column name\n",
    "meta_data_copy = meta_data_copy.rename(columns = {'id':'filename'})\n",
    "\n",
    "merged_train_data = pd.merge(train_wav , meta_data_copy , on=\"filename\")\n",
    "merged_train_data = merged_train_data.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index\"], axis=1)\n",
    "\n",
    "merged_test_data = pd.merge(test_wav , meta_data_copy , on=\"filename\")\n",
    "merged_test_data = merged_test_data.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import midi file tables\n",
    "# train_labels = pd.read_csv('../data/df_train_labels_consol.csv')\n",
    "# test_labels = pd.read_csv('../data/df_test_labels_consol.csv')\n",
    "\n",
    "# #combine train and test data\n",
    "# labels_frames = [train_labels,test_labels]\n",
    "# labels = pd.concat(labels_frames , ignore_index=True)\n",
    "\n",
    "# #create series with various midi features\n",
    "\n",
    "# #number of unique instruments\n",
    "# midi_nunique_inst = labels.groupby('file_name').agg({\"instrument\": \"nunique\"}).reset_index().rename(columns={\"instrument\": \"midi_nunique_inst\"})\n",
    "\n",
    "# #number of unique notes\n",
    "# midi_nunique_note = labels.groupby('file_name').agg({\"note\": \"nunique\"}).reset_index().rename(columns={\"note\": \"midi_nunique_note\"})\n",
    "\n",
    "# #total number of notes\n",
    "# midi_num_notes = labels.groupby('file_name').sum()[['note']].reset_index().rename(columns={'note':'midi_num_notes'})\n",
    "\n",
    "# #quintiles of the distribution of note values (pitches)\n",
    "# midi_min_note = labels.groupby('file_name').min()[['note']].reset_index().rename(columns={'note':'midi_min_note'})\n",
    "# midi_second_quintile_note = labels[['file_name','note']].groupby('file_name').quantile(q=0.25,interpolation='nearest')[['note']].reset_index().rename(columns={'note':'midi_second_quintile_note'})\n",
    "# midi_median_note = labels[['file_name','note']].groupby('file_name').quantile(interpolation='nearest')[['note']].reset_index().rename(columns={'note':'midi_median_note'})\n",
    "# midi_fourth_quintile_note = labels[['file_name','note']].groupby('file_name').quantile(q=0.75,interpolation='nearest')[['note']].reset_index().rename(columns={'note':'midi_fourth_quintile_note'})\n",
    "# midi_max_note = labels[['file_name','note']].groupby('file_name').max()[['note']].reset_index().rename(columns={'note':'midi_max_note'})\n",
    "\n",
    "# #average number of notes per instrument\n",
    "# midi_avg_notes_inst = labels.groupby(['file_name','instrument']).sum()[['note']].groupby('file_name').mean().reset_index().rename(columns={'note':'midi_avg_notes_inst'})\n",
    "\n",
    "# #merge all columns together\n",
    "# midi_features = midi_nunique_inst.merge(midi_nunique_note, on='file_name')\n",
    "# midi_features = midi_features.merge(midi_num_notes,on='file_name')\n",
    "# midi_features = midi_features.merge(midi_min_note,on='file_name')\n",
    "# midi_features = midi_features.merge(midi_second_quintile_note,on='file_name')\n",
    "# midi_features = midi_features.merge(midi_median_note,on='file_name')\n",
    "# midi_features = midi_features.merge(midi_fourth_quintile_note,on='file_name')\n",
    "# midi_features = midi_features.merge(midi_max_note,on='file_name')\n",
    "# midi_features = midi_features.merge(midi_avg_notes_inst,on='file_name')\n",
    "\n",
    "# midi_features.to_csv('../data/midi_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the metadata\n",
    "meta_data_copy = metadata.copy(deep=True)\n",
    "meta_data_copy.reset_index(inplace=True)\n",
    "#Rename column name\n",
    "meta_data_copy = meta_data_copy.rename(columns = {'id':'filename'})\n",
    "\n",
    "merged_train_data = pd.merge(train_wav , meta_data_copy , on=\"filename\")\n",
    "merged_train_data = merged_train_data.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index\"], axis=1)\n",
    "\n",
    "merged_test_data = pd.merge(test_wav , meta_data_copy , on=\"filename\")\n",
    "merged_test_data = merged_test_data.drop([\"composer\", \"composition\", \"movement\",\"source\",\"transcriber\",\"catalog_name\",\"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset of dataset for only max 2 instruments\n",
    "\n",
    "subset_list= ['Accompanied Cello','Accompanied Clarinet','Accompanied Violin','Solo Cello', 'Solo Flute', 'Solo Piano', 'Solo Violin', 'Violin and Harpsichord']\n",
    "subset_merged_train_data = merged_train_data.loc[merged_train_data['ensemble'].isin(subset_list)]\n",
    "subset_merged_test_data = merged_test_data.loc[merged_test_data['ensemble'].isin(subset_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Piano Quintet', 'Solo Piano', 'Piano Trio', 'Viola Quintet',\n",
       "       'String Quartet', 'Clarinet Quintet',\n",
       "       'Pairs Clarinet-Horn-Bassoon', 'Wind Quintet', 'Accompanied Cello',\n",
       "       'Accompanied Clarinet', 'Wind and Strings Octet', 'String Sextet',\n",
       "       'Piano Quartet', 'Horn Piano Trio', 'Solo Violin', 'Solo Flute',\n",
       "       'Solo Cello', 'Violin and Harpsichord',\n",
       "       'Clarinet-Cello-Piano Trio', 'Accompanied Violin', 'Wind Octet'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get list of unique ensembles\n",
    "ens_list = merged_train_data['ensemble'].unique()\n",
    "ens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Kieran_External_HD/Users/Kieran/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Volumes/Kieran_External_HD/Users/Kieran/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Map list of unique ensemble names to integer\n",
    "mapping = {item:i for i, item in enumerate(ens_list)}\n",
    "\n",
    "merged_train_data[\"ensemble\"] = merged_train_data[\"ensemble\"].apply(lambda x: mapping[x])\n",
    "subset_merged_train_data[\"ensemble\"] = subset_merged_train_data[\"ensemble\"].apply(lambda x: mapping[x])\n",
    "\n",
    "merged_test_data[\"ensemble\"] = merged_test_data[\"ensemble\"].apply(lambda x: mapping[x])\n",
    "subset_merged_test_data[\"ensemble\"] = subset_merged_test_data[\"ensemble\"].apply(lambda x: mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the original train test split given in kaggle\n",
    "X_original_train = merged_train_data.iloc[:,np.r_[:167,168]]\n",
    "X_original_test = merged_test_data.iloc[:,np.r_[:167,168]]\n",
    "\n",
    "y_original_train = merged_train_data.iloc[:,167:168]\n",
    "y_original_test = merged_test_data.iloc[:,167:168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the training and test data\n",
    "x_frames = [X_original_train,X_original_test]\n",
    "X = pd.concat(x_frames , ignore_index=True)\n",
    "\n",
    "y_frames = [y_original_train,y_original_test]\n",
    "y = pd.concat(y_frames , ignore_index=True)\n",
    "\n",
    "#Find the index position of viola quintet and drop it since there is only one ensemble of that type\n",
    "index_violaquintet = y[ y['ensemble'] == 3 ].index\n",
    "\n",
    "y.drop(index_violaquintet , inplace=True)\n",
    "X.drop(index_violaquintet , inplace=True)\n",
    "\n",
    "###########################################ADDING MIDI FEATURES################################\n",
    "#import and add midi features to input data\n",
    "midi_features = pd.read_csv('../data/midi_features.csv')\n",
    "midi_features.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "X = X.merge(midi_features,left_on = 'filename',right_on='file_name')\n",
    "X.drop('file_name',axis=1,inplace=True)\n",
    "# X['midi_note_density']=(X['midi_num_notes'] / X['seconds'])\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, test_size=0.20, stratify=y, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['harmonic', 'filename', 'mfcc_0', 'mfcc_1', 'mfcc_2', 'mfcc_3',\n",
       "       'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7',\n",
       "       ...\n",
       "       'seconds', 'midi_nunique_inst', 'midi_nunique_note', 'midi_num_notes',\n",
       "       'midi_min_note', 'midi_second_quintile_note', 'midi_median_note',\n",
       "       'midi_fourth_quintile_note', 'midi_max_note', 'midi_avg_notes_inst'],\n",
       "      dtype='object', length=177)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
