{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Evaluation of Top Performing Models\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt   \n",
    "%matplotlib inline\n",
    "from music21 import *\n",
    "from IPython.display import Audio\n",
    "from intervaltree import Interval,IntervalTree\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import csv features which were extracted from earlier Data PreProcessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w = pd.read_csv('../data/X_train_w.csv',index_col = 0)\n",
    "X_train_m = pd.read_csv('../data/X_train_m.csv',index_col = 0)\n",
    "X_train_c = pd.read_csv('../data/X_train_c.csv',index_col = 0)\n",
    "X_test_w = pd.read_csv('../data/X_test_w.csv',index_col = 0)\n",
    "X_test_m = pd.read_csv('../data/X_test_m.csv',index_col = 0)\n",
    "X_test_c = pd.read_csv('../data/X_test_c.csv',index_col = 0)\n",
    "y_train_w = pd.read_csv('../data/y_train_w.csv',index_col = 0)\n",
    "y_train_m = pd.read_csv('../data/y_train_m.csv',index_col = 0)\n",
    "y_train_c = pd.read_csv('../data/y_train_c.csv',index_col = 0)\n",
    "y_test_w = pd.read_csv('../data/y_test_w.csv',index_col = 0)\n",
    "y_test_m = pd.read_csv('../data/y_test_m.csv',index_col = 0)\n",
    "y_test_c = pd.read_csv('../data/y_test_c.csv',index_col = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Set Accuracy Results\n",
    "| Model               | Feature Set | Model Variant                                           | Highest CV Score | Mean CV Score |\n",
    "|---------------------|-------------|---------------------------------------------------------|------------------|---------------|\n",
    "| Logistic Regression | Spectral    | Baseline                                                | 94.23%           | 89.75%        |\n",
    "| Logistic Regression | Spectral    | PCA                                                     | 71.15%           | 68.83%        |\n",
    "| Logistic Regression | Midi        | Baseline                                                | 76.92%           | 71.10%        |\n",
    "| Logistic Regression | Midi        | PCA                                                     | 48.08%           | 41.49%        |\n",
    "| Logistic Regression | Combined    | Baseline                                                | 92.31%           | 85.56%        |\n",
    "| Logistic Regression | Combined    | PCA                                                     | 48.08%           | 45.64%        |\n",
    "| Naive Bayes         | Spectral    | Baseline                                                | 71.69%           | 68.41%        |\n",
    "| Naive Bayes         | Midi        | Baseline                                                | 75.00%           | 59.00%        |\n",
    "| Naive Bayes         | Combined    | Baseline                                                | 75.47%           | 73.00%        |\n",
    "| Decision Tree       | Spectral    | Baseline                                                | 80.77%           | 75.68%        |\n",
    "| Decision Tree       | Midi        | Baseline                                                | 86.79%           | 84.03%        |\n",
    "| Decision Tree       | Combined    | Baseline                                                | 94.23%           | 84.83%        |\n",
    "| Random Forest       | Spectral    | Baseline                                                | 86.54%           | 83.29%        |\n",
    "| Random Forest       | Spectral    | w/SMOTE                                                 | 100%             | 99.56%        |\n",
    "| Random Forest       | Spectral    | w/SMOTE +  Hyperparameter Tuning                        | ?                | ?             |\n",
    "| Random Forest       | Midi        | Baseline                                                | 94.34%           | 89.75%        |\n",
    "| Random Forest       | Midi        | w/SMOTE                                                 | 99.56%           | 99.34%        |\n",
    "| Random Forest       | Midi        | w/SMOTE + Hyperparameter Tuning                         | ?                | ?             |\n",
    "| Random Forest       | Combined    | Baseline                                                | 90.39%           | 86.72%        |\n",
    "| Random Forest       | Combined    | w/SMOTE                                                 | 100%             | 99.29%        |\n",
    "| Random Forest       | Combined    | w/SMOTE + Hyperparameter Tuning                         | ?                | ?             |\n",
    "| SVM                 | Spectral    | Baseline                                                | 67.39%           | 64.97%        |\n",
    "| SVM                 | Spectral    | w/Hyperparameter Tuning                                 | 95.65%           | 91.35%        |\n",
    "| SVM                 | Spectral    | w/Hyperparamater Tuning + PCA                           | 94.38%           | 90.47%        |\n",
    "| SVM                 | Spectral    | w/Hyperparameter Tuning + PCA + SMOTE                   | 100%             | 99.38%        |\n",
    "| SVM                 | Spectral    | w/Hyperparameter Tuning +  PCA + SMOTE + MinMaxScaler   | 77.33%           | 72.98%        |\n",
    "| SVM                 | Spectral    | w/Hyperparameter Tuning +  PCA + SMOTE + StandardScaler | 98.67%           | 97.24%        |\n",
    "| SVM                 | Midi        | Baseline                                                | 73.91%           | 73.17%        |\n",
    "| SVM                 | Midi        | w/Hyperparameter Tuning                                 | ?                | ?             |\n",
    "| SVM                 | Midi        | w/SMOTE                                                 | ?                | ?             |\n",
    "| SVM                 | Midi        | w/PCA                                                   | ?                | ?             |\n",
    "| SVM                 | Combined    | Baseline                                                | 73.91%           | 73.17%        |\n",
    "| SVM                 | Combined    | w/Hyperparameter Tuning                                 | ?                | ?             |\n",
    "| SVM                 | Combined    | w/SMOTE                                                 | ?                | ?             |\n",
    "| SVM                 | Combined    | w/PCA                                                   | ?                | ?             |\n",
    "| Neural Network      | Spectral    | Baseline (ADAM, 5 Hidden Layers)                        | 100%             | 100%          |\n",
    "| Neural Network      | Midi        | Baseline (ADAM, 5 Hidden Layers)                        | 84.85%           | 83.55%        |\n",
    "| Neural Network      | Combined    | Baseline (ADAM, 5 Hidden Layers)                        | 86.15%           | 81.82%        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Performing Models\n",
    "\n",
    "| Model               | Feature Set | Model Variant                                            | Max CV Score | Mean CV Score |\n",
    "|---------------------|-------------|----------------------------------------------------------|--------------|---------------|\n",
    "| Neural Network      | Spectral    | Baseline (ADAM, 5 Hidden Layers)                         | 100%         | 100%          |\n",
    "| Random Forest       | Spectral    | w/SMOTE                                                  | 100%         | 99.56%        |\n",
    "| SVM                 | Spectral    | w/Hyperparameter   Tuning + PCA + SMOTE                  | 100%         | 99.38%        |\n",
    "| Random Forest       | Midi        | w/SMOTE                                                  | 99.56%       | 99.34%        |\n",
    "| Random Forest       | Combined    | w/SMOTE                                                  | 100%         | 99.29%        |\n",
    "| SVM                 | Spectral    | w/Hyperparameter   Tuning + PCA + SMOTE + StandardScaler | 98.67%       | 97.24%        |\n",
    "| SVM                 | Spectral    | w/Hyperparameter   Tuning                                | 95.65%       | 91.35%        |\n",
    "| SVM                 | Spectral    | w/Hyperparamater   Tuning + PCA                          | 94.38%       | 90.47%        |\n",
    "| Logistic Regression | Spectral    | Baseline                                                 | 94.23%       | 89.75%        |\n",
    "| Random Forest       | Midi        | Baseline                                                 | 94.34%       | 89.75%        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network - Spectral - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(176, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(90, activation='relu'),\n",
    "    tf.keras.layers.Dense(80, activation='relu'),\n",
    "    tf.keras.layers.Dense(70, activation='relu'),\n",
    "    tf.keras.layers.Dense(60, activation='relu'),\n",
    "    tf.keras.layers.Dense(21)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train_w, y_train_w, epochs=200)\n",
    "predictions = rf.predict(X_test_w)\n",
    "f1 = f1_score(y_test_w, predictions)\n",
    "print(\"F1 score = {:.5f}: {:.2%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Spectral - w/SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-9c41a22ca26d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_SMOTE_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_SMOTE_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F1 score = {:.5f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "# todo: I think we need to re-import the data for this cell, if this is run multiple times then y_train_w gets overwritten\n",
    "y_train_w = pd.read_csv('../data/y_train_w.csv',index_col = 0)\n",
    "\n",
    "#Drop any ensemble types with counts below 6. This because Expected n_neighbors <= n_samples,  \n",
    "#but n_samples = 3, n_neighbors = 6\n",
    "counts = y_train_w['ensemble'].value_counts()\n",
    "X_train_w = X_train_w[~y_train_w['ensemble'].isin(counts[counts < 6].index)]\n",
    "y_train_w = y_train_w[~y_train_w['ensemble'].isin(counts[counts < 6].index)]\n",
    "\n",
    "# Fit and apply the transform\n",
    "X_SMOTE_w, y_SMOTE_w = SMOTE(random_state=101).fit_resample(X_train_w, y_train_w)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_SMOTE_w, y_SMOTE_w)\n",
    "predictions = rf.predict(X_test_w)\n",
    "f1 = f1_score(y_test_w, predictions)\n",
    "print('Test Set F1 score = {:.5f}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Spectral - w/Hyperparameter Tuning + PCA + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop any ensemble types with counts below 6\n",
    "counts = y_train_w['ensemble'].value_counts()\n",
    "X_train_w_smote = X_train_w[~y_train_w['ensemble'].isin(counts[counts < 6].index)]\n",
    "y_train_w_smote = y_train_w[~y_train_w['ensemble'].isin(counts[counts < 6].index)]\n",
    "\n",
    "# fit and apply the transform\n",
    "X_SMOTE, y_SMOTE = SMOTE().fit_resample(X_train_w_smote, y_train_w_smote.values.ravel())\n",
    "\n",
    "#Perform PCA with 15 components\n",
    "pca=PCA(n_components = 15)\n",
    "pca.fit(X_SMOTE)\n",
    "train_pca_w_smote = pca.transform(X_SMOTE)\n",
    "X_test_w_pca = pca.transform(X_test_w)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': np.logspace(-4, 4, 20), \n",
    "              'gamma': np.logspace(-3, 2, 6),\n",
    "              'kernel': ['linear','rbf','poly']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid , cv=5)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(train_pca_w_smote, y_SMOTE)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "#Create SVM model with best hyperparameters, PCA and SMOTE\n",
    "\n",
    "svm = make_pipeline(SVC(kernel=grid.best_params_['kernel'], C = grid.best_params_['C'] , gamma=grid.best_params_['gamma']))\n",
    "svm.fit(train_pca_w_smote, y_SMOTE)\n",
    "predictions = svm.predict(X_test_w_pca)\n",
    "f1_score = f1_score(y_test_w, predictions)\n",
    "print(\"Test Set F1-score: {:.2%}\".format(f1_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Midi - w/SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-de5a99a78ce9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_SMOTE_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_SMOTE_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Set F1-score: {:.2%}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "# todo: I think we need to re-import the data for this cell, if this is run multiple times then y_train_w gets overwritten\n",
    "y_train_m = pd.read_csv('../data/y_train_m.csv',index_col = 0)\n",
    "y_test_m = pd.read_csv('../data/y_test_m.csv',index_col = 0)\n",
    "\n",
    "#Drop any ensemble types with counts below 6. This because Expected n_neighbors <= n_samples,  \n",
    "#but n_samples = 3, n_neighbors = 6\n",
    "counts = y_train_m['ensemble'].value_counts()\n",
    "X_train_m = X_train_m[~y_train_m['ensemble'].isin(counts[counts < 6].index)]\n",
    "y_train_m = y_train_m[~y_train_m['ensemble'].isin(counts[counts < 6].index)]\n",
    "\n",
    "# Fit and apply the transform\n",
    "X_SMOTE_m, y_SMOTE_m = SMOTE(random_state=101).fit_resample(X_train_m, y_train_m)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_SMOTE_m, y_SMOTE_m)\n",
    "predictions = rf.predict(X_test_m)\n",
    "f1 = f1_score(y_test_m, predictions, average = 'weighted')\n",
    "\n",
    "print(\"Test Set F1-score: {:.2%}\".format(f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Combined - w/SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: I think we need to re-import the data for this cell, if this is run multiple times then y_train_w gets overwritten\n",
    "y_train_c = pd.read_csv('../data/y_train_c.csv',index_col = 0)\n",
    "\n",
    "#Drop any ensemble types with counts below 6. This because Expected n_neighbors <= n_samples,  \n",
    "#but n_samples = 3, n_neighbors = 6\n",
    "counts = y_train_c['ensemble'].value_counts()\n",
    "X_train_c = X_train_c[~y_train_c['ensemble'].isin(counts[counts < 6].index)]\n",
    "y_train_c = y_train_c[~y_train_c['ensemble'].isin(counts[counts < 6].index)]\n",
    "\n",
    "X_SMOTE_c, y_SMOTE_c = SMOTE(random_state=101).fit_resample(X_train_c, y_train_c)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_SMOTE_c, y_SMOTE_c)\n",
    "predictions = rf.predict(X_test_c)\n",
    "f1_score = f1_score(y_test_w, predictions,average='weighted')\n",
    "print(\"Test Set F1-score: {:.2%}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Spectral - w/Hyperparameter Tuning + PCA + SMOTE + StandardScaler\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Standard Scaler Application\n",
    "\n",
    "#Perform PCA with 15 components\n",
    "pca=PCA(n_components = 15)\n",
    "pca.fit(X_SMOTE)\n",
    "train_pca_w_smote = pca.transform(X_SMOTE)\n",
    "X_test_w_pca = pca.transform(X_test_w)\n",
    "\n",
    "\n",
    "#Create SVM model with best hyperparameters, PCA and SMOTE and StandardScaler\n",
    "\n",
    "svm = make_pipeline(StandardScaler() ,SVC(kernel=grid.best_params_['kernel'], C = grid.best_params_['C'] , gamma=grid.best_params_['gamma']))\n",
    "svm.fit(train_pca_w_smote, y_SMOTE)\n",
    "\n",
    "\n",
    "predictions = svm.predict(X_test_w_pca)\n",
    "f1_score = f1_score(y_test_w, predictions,average='weighted')\n",
    "print(\"Test Set F1-score: {:.2%}\".format(f1_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Spectral - w/Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find best hyperparameters\n",
    "param_grid = {'C': np.logspace(-4, 4, 20), \n",
    "              'gamma': np.logspace(-3, 2, 6),                     \n",
    "              'kernel': ['linear','rbf','poly']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train_w, y_train_w.values.ravel())\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "\n",
    "#Create Model with best hyperparameters\n",
    "\n",
    "svm = make_pipeline(SVC(kernel=grid.best_params_['kernel'], C = grid.best_params_['C'] , gamma=grid.best_params_['gamma']))\n",
    "svm.fit(X_train_w, y_train_w.values.ravel())\n",
    "predictions = svm.predict(X_test_w)\n",
    "f1_score = f1_score(y_test_w, predictions,average='weighted')\n",
    "print(\"Test Set F1-score: {:.2%}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Spectral - W/Hyperparameter Tuning + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform PCA with 15 components\n",
    "pca=PCA(n_components = 15)\n",
    "pca.fit(X_train_w)\n",
    "train_pca_w = pca.transform(X_train_w)\n",
    "X_test_w_pca = pca.transform(X_test_w)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': np.logspace(-4, 4, 20), \n",
    "              'gamma': np.logspace(-3, 2, 6),\n",
    "              'kernel': ['linear','rbf','poly']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid , cv=5)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(train_pca_w, y_train_w.values.ravel())\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "#Create Model with best hyperparameters and PCA\n",
    "svm = make_pipeline(SVC(kernel=grid.best_params_['kernel'], C = grid.best_params_['C'] , gamma=grid.best_params_['gamma']))\n",
    "svm.fit(train_pca_w, y_train_w.values.ravel())\n",
    "predictions = svm.predict(X_test_w_pca)\n",
    "f1_score = f1_score(y_test_w, predictions,average='weighted')\n",
    "print(\"Test Set F1-score: {:.2%}\".format(f1_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Spectral - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Baseline Logistic Model\n",
    "lr = LogisticRegression(C = 0.5, solver='liblinear', multi_class='auto')\n",
    "lr.fit(np.array(X_train_w), np.array(y_train_w))\n",
    "predictions = lr.predict(X_test_w)\n",
    "f1 = f1_score(y_test_w, predictions,average='weighted')\n",
    "print(\"Test Set F1-score: {:.2%}\".format(f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Midi - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a0e1c9b26d6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Set F1-score: {:.2%}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_m, y_train_m)\n",
    "predictions = rf.predict(X_test_m)\n",
    "f1 = f1_score(y_test_w, predictions,average='weighted')\n",
    "print(\"Test Set F1-score: {:.2%}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Test Results\n",
    "\n",
    "| Model               | Feature Set | Model Variant                                            | Mean CV Score | Test Score |\n",
    "|---------------------|-------------|----------------------------------------------------------|---------------|------------|\n",
    "| Neural Network      | Spectral    | Baseline (ADAM, 5 Hidden Layers)                         | 100%          | ?          |\n",
    "| Random Forest       | Spectral    | w/SMOTE                                                  | 99.56%        | 75.76%     |\n",
    "| SVM                 | Spectral    | w/Hyperparameter   Tuning + PCA + SMOTE                  | 99.38%        | 78.79%     |\n",
    "| Random Forest       | Midi        | w/SMOTE                                                  | 99.34%        | 83.33%     |\n",
    "| Random Forest       | Combined    | w/SMOTE                                                  | 99.29%        | 80.30%     |\n",
    "| SVM                 | Spectral    | w/Hyperparameter   Tuning + PCA + SMOTE + StandardScaler | 97.24%        | 74.24%     |\n",
    "| SVM                 | Spectral    | w/Hyperparameter   Tuning                                | 91.35%        | 77.27%     |\n",
    "| SVM                 | Spectral    | w/Hyperparamater   Tuning + PCA                          | 90.47%        | 74.24%     |\n",
    "| Logistic Regression | Spectral    | Baseline                                                 | 89.75%        | 78.79%     |\n",
    "| Random Forest       | Midi        | Baseline                                                 | 89.75%        | 83.33%     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
